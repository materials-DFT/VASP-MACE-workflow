/Users/924322630/.local/lib/python3.12/site-packages/nequip/scripts/train.py:92: UserWarning: 

!!! WARNING !!!
The `global_options` section is no longer a required section in config files and will be ignored. TF32 settings should now be configured using the TF32Scheduler callback:

callbacks:
  - _target_: nequip.train.callbacks.TF32Scheduler
    schedule:
      0: true

See the documentation for more details.

  warnings.warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name         | Type           | Params | Mode 
--------------------------------------------------------
0 | model        | ModuleDict     | 129 K  | train
1 | loss         | MetricsManager | 0      | eval 
2 | val_metrics  | ModuleList     | 0      | eval 
3 | test_metrics | ModuleList     | 0      | eval 
4 | ema          | EMAWeights     | 0      | train
--------------------------------------------------------
129 K     Trainable params
0         Non-trainable params
129 K     Total params
0.517     Total estimated model params size (MB)
61        Modules in train mode
12        Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/Users/924322630/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/Users/924322630/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.
/Users/924322630/.local/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 12 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
`Trainer.fit` stopped: `max_epochs=500` reached.
Restoring states from the checkpoint path at /Users/924322630/allegro_mno2k/54/4_gpus/models/best.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
Loaded model weights from the checkpoint at /Users/924322630/allegro_mno2k/54/4_gpus/models/best.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/Users/924322630/.local/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:216: Using `DistributedSampler` with the dataloaders. During `trainer.validate()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
